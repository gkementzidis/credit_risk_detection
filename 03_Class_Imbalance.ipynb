{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 03: Class Imbalance\n",
    "Explore imbalance between the two classes (defaul and non-default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32581, 12)\n"
     ]
    }
   ],
   "source": [
    "# loading the dataset\n",
    "data = pd.read_csv('credit_risk_dataset.csv')\n",
    "print(data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Cleaning\n",
    "\n",
    "- remove odd data (e.g., age > 120 years, employment history length > age + 15 years)\n",
    "- drop duplicates\n",
    "- replace ordinal categorical variables or binary nominal variables with discrete numerical variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop outlier and unreasonable data\n",
    "data = data[(data['person_emp_length'].isnull()) | (data['person_age'] >= 15+data['person_emp_length'])]\n",
    "data = data[data['person_age']<100]\n",
    "\n",
    "# drop duplicates\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "# replace strings with integers\n",
    "data['cb_person_default_on_file'].replace(['Y', 'N'], [1, 0], inplace = True)\n",
    "data['loan_grade'].replace(['A', 'B', 'C', 'D', 'E', 'F', 'G'], [1, 2, 3, 4, 5, 6, 7], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HANDLE MISSING VALUES (Notebook 01)\n",
    "# PART 1: person_emp_length\n",
    "# replace the missing values in the original dataset with the median\n",
    "data['person_emp_length'].fillna(data['person_emp_length'].median(), inplace = True)\n",
    "\n",
    "# PART 2: loan_int_rate\n",
    "# drop NA values to facilitate computations\n",
    "data_noNA = data.dropna()\n",
    "\n",
    "X = data_noNA[['person_age', 'person_income', 'loan_amnt', 'cb_person_cred_hist_length', 'loan_grade', 'cb_person_default_on_file', 'loan_percent_income']]\n",
    "X.loc[:, 'person_income'] = np.log(X['person_income'])\n",
    "X.loc[:, 'loan_amnt'] = np.log(X['loan_amnt'])\n",
    "y = data_noNA['loan_int_rate']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 34)\n",
    "\n",
    "# train a linear regression model\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "# predict the test set results\n",
    "y_pred = regressor.predict(X_test)\n",
    "\n",
    "data_NA = data[data['loan_int_rate'].isnull()]\n",
    "data_NA_X = data_NA[['person_age', 'person_income', 'loan_amnt', 'cb_person_cred_hist_length', 'loan_grade', 'cb_person_default_on_file', 'loan_percent_income', 'loan_int_rate']]\n",
    "data_NA_X.loc[:, 'person_income'] = np.log(data_NA_X['person_income'])\n",
    "data_NA_X.loc[:, 'loan_amnt'] = np.log(data_NA_X['loan_amnt'])\n",
    "\n",
    "data_NA_X.loc[:, 'loan_int_rate'] = regressor.predict(data_NA_X[['person_age', 'person_income', 'loan_amnt', 'cb_person_cred_hist_length', 'loan_grade', 'cb_person_default_on_file', 'loan_percent_income']])\n",
    "\n",
    "data.update(data_NA_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_status\n",
       "0    25321\n",
       "1     7088\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['loan_status'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a clear sign of **class imbalance**.\n",
    "\n",
    "We are dealing with a classification problem to predict credit risk. Because of the imbalance of the two classesc (positive: default, negative: non-default), any model may lean on the predicting the majority (negative) class. However, in cases of credit risk, we want to make sure that among the real positive cases, we identify as many as possible. We want a high **recall** (in addition to high accuracy, precision, F1 score, AUC-ROC). We will have to balance the two datasets to achieve this. Common techniques include:\n",
    "- Class weight adjustment\n",
    "- Undersampling the majority class (e.g., random undersampling)\n",
    "- Oversampling the minority class (e.g., random oversampling, SMOTE-ENC for nominal categorical variables)\n",
    "\n",
    "Due to its simplicity, we will first resort to class weight adjustment for the baseline (logistic regression) model. For other, more complicated models, we may conduct a combination of undersampling the majority class and random oversampling the minority class, since creating synthetic data with nominal categorical, ordinal categotical, and discrete numeric features might be a bit challenging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the target variables\n",
    "y = data['loan_status']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0.6399628766636388, 1: 2.2861879232505644}\n"
     ]
    }
   ],
   "source": [
    "# compute the class weights\n",
    "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)\n",
    "class_weights = {0: class_weights[0], 1: class_weights[1]}\n",
    "print(class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Under- & Over-sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loan_status\n",
       "0    10000\n",
       "1    10000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a copy of the data frame\n",
    "data_copy = data.copy()\n",
    "\n",
    "# oversample the minority class and undersample the majority class\n",
    "positiveSample = data_copy[data_copy['loan_status']==1].sample(n=10000, replace=True, random_state=1)\n",
    "negativeSample = data_copy[data_copy['loan_status']==0].sample(n=10000, replace=False, random_state=1)\n",
    "data_balanced = pd.concat([positiveSample, negativeSample]).sample(frac=1, random_state=12)\n",
    "data_balanced['loan_status'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rgan_pytorch",
   "language": "python",
   "name": "rgan_pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
